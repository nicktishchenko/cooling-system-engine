{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install textacy\n",
    "# %pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Verbs: ['performed', 'replaced', 'inspected', 'lubricated', 'needed', 'shut', 'needed', 'inspected', 'adjusted', 'needed', 'cleaned', 'checked', 'inspected', 'inspected', 'tested', 'inspected', 'tested', 'inspected', 'checked', 'inspected', 'inspected', 'cleaned', 'replaced', 'brushed', 'needed', 'inspected', 'lubricated', 'needed', 'checked', 'walk', 'insfted', 'checked', 'inspected', 'inspected', 'replaced', 'brushed', 'needed', 'inspectedcated', 'inspected', 'checked', 'checked', 'inspected', 'inspected', 'inspected', 'inspected', 'inspected', 'cleaned', 'inspected', 'inspected', 'lubricated', 'needed', 'descaled', 'inspected', 'adjusted', 'needed', 'replaced', 'neededted']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline, logging\n",
    "\n",
    "# Suppress warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model for POS tagging\n",
    "model_name = 'vblagoje/bert-english-uncased-finetuned-pos'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Define a function to find all action verbs in the text using the BERT model\n",
    "def find_action_verbs(text):\n",
    "    # Use the BERT model for POS tagging\n",
    "    nlp = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    pos_results = nlp(text)\n",
    "    \n",
    "    # Find all action verbs and handle sub-word tokens\n",
    "    action_verbs = []\n",
    "    current_word = \"\"\n",
    "    for result in pos_results:\n",
    "        if result['entity'] == 'VERB':  # Check if the entity is a verb\n",
    "            if result['word'].startswith('##'):\n",
    "                current_word += result['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    action_verbs.append(current_word)\n",
    "                current_word = result['word']\n",
    "    if current_word:\n",
    "        action_verbs.append(current_word)\n",
    "    \n",
    "    return action_verbs\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\n",
    "PERFORMED PM PER SCOPE HVAC TASKS REPLACED AIR FILTERS VISUALLY INSPECTED FOR REFRIGERANT LEAKS LUBRICATED ALL BEARINGS AS NEEDED SHUT OFF WATER SUPPLY  \n",
    "FALL VISIT AS NEEDED  INSPECTED BELTS AND ADJUSTED AS NEEDED CLEANED CONDENSATE LINES CHECKED CONTACTORS VISUALLY INSPECTED EVAPORATOR AND CONDENSER COILS \n",
    "INSPECTED AND TESTED HEATING CIRCUIT FOR OPERATION INSPECTED AND TESTED EACH CONDENSATE PUMP IF APPLICABLE REFRIGERATIONS TASKS INSPECTED ALL HINGES AND \n",
    "GASKETS CHECKED ELECTRICAL CONTACTS  CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED FOR LEAKS CLEANED ALL PRE FILTER MEDIA AND \n",
    "REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS AS NEEDED CHECKED CONTROLS CALIBRATION AND \n",
    "OPERATION WALK IN TASKS INSPECFTED ALL HINGES AND GASKETS CHECKED ELECTRICAL CONTACTS CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED \n",
    "FOR LEAKS CLEANE DALL PRE FILTER MEDIA AND REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "INSPECTED SIGHT GLASS CHECKED CONTROL CALIBRATION AND OPERATION ICE MACHINE TASKS CHECKED ICE PRODUCTION THICKNESS AND SENSING PROBES INSPECTED DOOR AND GASKET \n",
    "VISUALLY INSPECTED BIN AND BIN TSTAT INSPECTED WATER PUMPS AND DISTRIBUTION TUBES VISUALLY INSPECTED WATER FILTERS INSPECTED FOR ANY LEAKS CLEANED CONDENSER COILS \n",
    "INSPECTED ALL ELECTRICAL COMPONENTS INSPECTED FAN MOTOR  BLADES   BEARINGS   LUBRICATED AS NEEDED DESCALED ICE MACHINE EXHAUST FAN TASKS INSPECTED ROOF FAN BELTS AND \n",
    "SHEAVES ADJUSTED AS NEEDED REPLACED BELTS AS NEEDED  20X25X2 PLEATED FILTER HIGH EFFICIENCY\n",
    "\"\"\"\n",
    "\n",
    "# Find all action verbs in the text\n",
    "action_verbs = find_action_verbs(text)\n",
    "\n",
    "# Print the results\n",
    "print(\"Action Verbs:\", action_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Verbs: ['performed', 'replaced', 'inspected', 'lubricated', 'needed', 'shut', 'needed', 'inspected', 'adjusted', 'needed', 'cleaned', 'checked', 'inspected', 'inspected', 'tested', 'inspected', 'tested', 'inspected', 'checked', 'inspected', 'inspected', 'cleaned', 'replaced', 'brushed', 'needed', 'inspected', 'lubricated', 'needed', 'checked', 'walk', 'insfted', 'checked', 'inspected', 'inspected', 'replaced', 'brushed', 'needed', 'inspectedcated', 'inspected', 'checked', 'checked', 'inspected', 'inspected', 'inspected', 'inspected', 'inspected', 'cleaned', 'inspected', 'inspected', 'lubricated', 'needed', 'descaled', 'inspected', 'adjusted', 'needed', 'replaced', 'neededted']\n",
      "Verb-Object Pairs: []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline, logging\n",
    "\n",
    "# Suppress warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model for POS tagging\n",
    "model_name = 'vblagoje/bert-english-uncased-finetuned-pos'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Define a function to find all action verbs in the text using the BERT model\n",
    "def find_action_verbs(text, nlp_pipeline):\n",
    "    # Use the BERT model for POS tagging\n",
    "    pos_results = nlp_pipeline(text)\n",
    "    \n",
    "    # Find all action verbs and handle sub-word tokens\n",
    "    action_verbs = []\n",
    "    current_word = \"\"\n",
    "    for result in pos_results:\n",
    "        if result['entity'] == 'VERB':  # Check if the entity is a verb\n",
    "            if result['word'].startswith('##'):\n",
    "                current_word += result['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    action_verbs.append(current_word)\n",
    "                current_word = result['word']\n",
    "    if current_word:\n",
    "        action_verbs.append(current_word)\n",
    "    \n",
    "    return action_verbs\n",
    "\n",
    "# Define a function to find objects for each action verb\n",
    "def find_objects_for_verbs(text, action_verbs, nlp_pipeline):\n",
    "    verb_object_pairs = []\n",
    "    for i, verb in enumerate(action_verbs):\n",
    "        start_index = text.find(verb)\n",
    "        end_index = text.find(action_verbs[i + 1]) if i + 1 < len(action_verbs) else len(text)\n",
    "        substring = text[start_index:end_index]\n",
    "        \n",
    "        # Use the BERT model for POS tagging to find objects in the substring\n",
    "        pos_results = nlp_pipeline(substring)\n",
    "        objects = []\n",
    "        current_word = \"\"\n",
    "        for result in pos_results:\n",
    "            if result['entity'] in ('B-NP', 'I-NP'):  # Check if the entity is a noun phrase (object)\n",
    "                if result['word'].startswith('##'):\n",
    "                    current_word += result['word'][2:]\n",
    "                else:\n",
    "                    if current_word:\n",
    "                        objects.append(current_word)\n",
    "                    current_word = result['word']\n",
    "        if current_word:\n",
    "            objects.append(current_word)\n",
    "        \n",
    "        # Pair the verb with the first object found in the substring\n",
    "        if objects:\n",
    "            verb_object_pairs.append((verb, ' '.join(objects)))\n",
    "    \n",
    "    return verb_object_pairs\n",
    "\n",
    "# Initialize the pipeline\n",
    "nlp_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=0 if torch.backends.mps.is_available() else -1)\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\n",
    "PERFORMED PM PER SCOPE HVAC TASKS REPLACED AIR FILTERS VISUALLY INSPECTED FOR REFRIGERANT LEAKS LUBRICATED ALL BEARINGS AS NEEDED SHUT OFF WATER SUPPLY  \n",
    "FALL VISIT AS NEEDED  INSPECTED BELTS AND ADJUSTED AS NEEDED CLEANED CONDENSATE LINES CHECKED CONTACTORS VISUALLY INSPECTED EVAPORATOR AND CONDENSER COILS \n",
    "INSPECTED AND TESTED HEATING CIRCUIT FOR OPERATION INSPECTED AND TESTED EACH CONDENSATE PUMP IF APPLICABLE REFRIGERATIONS TASKS INSPECTED ALL HINGES AND \n",
    "GASKETS CHECKED ELECTRICAL CONTACTS  CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED FOR LEAKS CLEANED ALL PRE FILTER MEDIA AND \n",
    "REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS AS NEEDED CHECKED CONTROLS CALIBRATION AND \n",
    "OPERATION WALK IN TASKS INSPECFTED ALL HINGES AND GASKETS CHECKED ELECTRICAL CONTACTS CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED \n",
    "FOR LEAKS CLEANE DALL PRE FILTER MEDIA AND REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "INSPECTED SIGHT GLASS CHECKED CONTROL CALIBRATION AND OPERATION ICE MACHINE TASKS CHECKED ICE PRODUCTION THICKNESS AND SENSING PROBES INSPECTED DOOR AND GASKET \n",
    "VISUALLY INSPECTED BIN AND BIN TSTAT INSPECTED WATER PUMPS AND DISTRIBUTION TUBES VISUALLY INSPECTED WATER FILTERS INSPECTED FOR ANY LEAKS CLEANED CONDENSER COILS \n",
    "INSPECTED ALL ELECTRICAL COMPONENTS INSPECTED FAN MOTOR  BLADES   BEARINGS   LUBRICATED AS NEEDED DESCALED ICE MACHINE EXHAUST FAN TASKS INSPECTED ROOF FAN BELTS AND \n",
    "SHEAVES ADJUSTED AS NEEDED REPLACED BELTS AS NEEDED  20X25X2 PLEATED FILTER HIGH EFFICIENCY\n",
    "\"\"\"\n",
    "\n",
    "# Find all action verbs in the text\n",
    "action_verbs = find_action_verbs(text, nlp_pipeline)\n",
    "print(\"Action Verbs:\", action_verbs)\n",
    "\n",
    "# Find objects for each action verb\n",
    "verb_object_pairs = find_objects_for_verbs(text, action_verbs, nlp_pipeline)\n",
    "\n",
    "# Print the results\n",
    "print(\"Verb-Object Pairs:\", verb_object_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Action Verbs: ['performed', 'replaced', 'inspected', 'lubricated', 'needed', 'shut', 'needed', 'inspected', 'adjusted', 'needed', 'cleaned', 'checked', 'inspected', 'inspected', 'tested', 'inspected', 'tested', 'inspected', 'checked', 'inspected', 'inspected', 'cleaned', 'replaced', 'brushed', 'needed', 'inspected', 'lubricated', 'needed', 'checked', 'walk', 'insfted', 'checked', 'inspected', 'inspected', 'replaced', 'brushed', 'needed', 'inspectedcated', 'inspected', 'checked', 'checked', 'inspected', 'inspected', 'inspected', 'inspected', 'inspected', 'cleaned', 'inspected', 'inspected', 'lubricated', 'needed', 'descaled', 'inspected', 'adjusted', 'needed', 'replaced', 'neededted']\n",
      "Verb-Object Pairs: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline, logging\n",
    "\n",
    "# Suppress warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model for POS tagging\n",
    "model_name = 'vblagoje/bert-english-uncased-finetuned-pos'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Define a function to find all action verbs in the text using the BERT model\n",
    "def find_action_verbs(text, nlp_pipeline):\n",
    "    # Use the BERT model for POS tagging\n",
    "    pos_results = nlp_pipeline(text)\n",
    "    \n",
    "    # Find all action verbs and handle sub-word tokens\n",
    "    action_verbs = []\n",
    "    current_word = \"\"\n",
    "    for result in pos_results:\n",
    "        if result['entity'] == 'VERB':  # Check if the entity is a verb\n",
    "            if result['word'].startswith('##'):\n",
    "                current_word += result['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    action_verbs.append(current_word)\n",
    "                current_word = result['word']\n",
    "    if current_word:\n",
    "        action_verbs.append(current_word)\n",
    "    \n",
    "    return action_verbs\n",
    "\n",
    "\n",
    "# Initialize the pipeline\n",
    "nlp_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=0 if torch.backends.mps.is_available() else -1)\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\n",
    "PERFORMED PM PER SCOPE HVAC TASKS REPLACED AIR FILTERS VISUALLY INSPECTED FOR REFRIGERANT LEAKS LUBRICATED ALL BEARINGS AS NEEDED SHUT OFF WATER SUPPLY  \n",
    "FALL VISIT AS NEEDED  INSPECTED BELTS AND ADJUSTED AS NEEDED CLEANED CONDENSATE LINES CHECKED CONTACTORS VISUALLY INSPECTED EVAPORATOR AND CONDENSER COILS \n",
    "INSPECTED AND TESTED HEATING CIRCUIT FOR OPERATION INSPECTED AND TESTED EACH CONDENSATE PUMP IF APPLICABLE REFRIGERATIONS TASKS INSPECTED ALL HINGES AND \n",
    "GASKETS CHECKED ELECTRICAL CONTACTS  CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED FOR LEAKS CLEANED ALL PRE FILTER MEDIA AND \n",
    "REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS AS NEEDED CHECKED CONTROLS CALIBRATION AND \n",
    "OPERATION WALK IN TASKS INSPECFTED ALL HINGES AND GASKETS CHECKED ELECTRICAL CONTACTS CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED \n",
    "FOR LEAKS CLEANE DALL PRE FILTER MEDIA AND REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "INSPECTED SIGHT GLASS CHECKED CONTROL CALIBRATION AND OPERATION ICE MACHINE TASKS CHECKED ICE PRODUCTION THICKNESS AND SENSING PROBES INSPECTED DOOR AND GASKET \n",
    "VISUALLY INSPECTED BIN AND BIN TSTAT INSPECTED WATER PUMPS AND DISTRIBUTION TUBES VISUALLY INSPECTED WATER FILTERS INSPECTED FOR ANY LEAKS CLEANED CONDENSER COILS \n",
    "INSPECTED ALL ELECTRICAL COMPONENTS INSPECTED FAN MOTOR  BLADES   BEARINGS   LUBRICATED AS NEEDED DESCALED ICE MACHINE EXHAUST FAN TASKS INSPECTED ROOF FAN BELTS AND \n",
    "SHEAVES ADJUSTED AS NEEDED REPLACED BELTS AS NEEDED  20X25X2 PLEATED FILTER HIGH EFFICIENCY\n",
    "\"\"\"\n",
    "\n",
    "# remove special characters from text\n",
    "text = re.sub(r'[^A-Za-z0-9\\s]+', '', text)\n",
    "\n",
    "# Find all action verbs in the text\n",
    "action_verbs = find_action_verbs(text, nlp_pipeline)\n",
    "print(\"Extracted Action Verbs:\", action_verbs)\n",
    "\n",
    "# Normalize case\n",
    "text = text.lower()\n",
    "action_verbs = [verb.lower() for verb in action_verbs]\n",
    "\n",
    "# Define a function to find objects for each action verb\n",
    "def find_objects_for_verbs(text, action_verbs, nlp_pipeline):\n",
    "    verb_object_pairs = []\n",
    "    for i, verb in enumerate(action_verbs):\n",
    "        start_index = text.find(verb)\n",
    "        end_index = text.find(action_verbs[i + 1]) if i + 1 < len(action_verbs) else len(text)\n",
    "        substring = text[start_index:end_index]\n",
    "        \n",
    "        # Use the BERT model for POS tagging to find objects in the substring\n",
    "        pos_results = nlp_pipeline(substring)\n",
    "        objects = []\n",
    "        current_word = \"\"\n",
    "        for result in pos_results:\n",
    "            if result['entity'].startswith('B-') or result['entity'].startswith('I-'):  # Check if the entity is a noun phrase (object)\n",
    "                if result['word'].startswith('##'):\n",
    "                    current_word += result['word'][2:]\n",
    "                else:\n",
    "                    if current_word:\n",
    "                        objects.append(current_word)\n",
    "                    current_word = result['word']\n",
    "        if current_word:\n",
    "            objects.append(current_word)\n",
    "        \n",
    "        # Pair the verb with the first object found in the substring\n",
    "        if objects:\n",
    "            verb_object_pairs.append((verb, ' '.join(objects)))\n",
    "    \n",
    "    return verb_object_pairs\n",
    "\n",
    "\n",
    "\n",
    "# Find objects for each action verb\n",
    "verb_object_pairs = find_objects_for_verbs(text, action_verbs, nlp_pipeline)\n",
    "\n",
    "# Print the results\n",
    "print(\"Verb-Object Pairs:\", verb_object_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "8 -1\n"
     ]
    }
   ],
   "source": [
    "print(len(action_verbs))\n",
    "print(start_index,end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Action Verbs: ['performed', 'replaced', 'inspected', 'lubricated', 'needed', 'shut', 'needed', 'inspected', 'adjusted', 'needed', 'cleaned', 'checked', 'inspected', 'inspected', 'tested', 'inspected', 'tested', 'inspected', 'checked', 'inspected', 'inspected', 'cleaned', 'replaced', 'brushed', 'needed', 'inspected', 'lubricated', 'needed', 'checked', 'walk', 'insfted', 'checked', 'inspected', 'inspected', 'replaced', 'brushed', 'needed', 'inspectedcated', 'inspected', 'checked', 'checked', 'inspected', 'inspected', 'inspected', 'inspected', 'inspected', 'cleaned', 'inspected', 'inspected', 'lubricated', 'needed', 'descaled', 'inspected', 'adjusted', 'needed', 'replaced', 'neededted']\n",
      "Verb: 'performed', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'replaced', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'lubricated', Length: 10\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'shut', Length: 4\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'adjusted', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'cleaned', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'tested', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'tested', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'cleaned', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'replaced', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'brushed', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'lubricated', Length: 10\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'walk', Length: 4\n",
      "Text Substring: ''\n",
      "Verb: 'insfted', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'replaced', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'brushed', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'inspectedcated', Length: 14\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'checked', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'cleaned', Length: 7\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'lubricated', Length: 10\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'descaled', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'inspected', Length: 9\n",
      "Text Substring: ''\n",
      "Verb: 'adjusted', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'needed', Length: 6\n",
      "Text Substring: ''\n",
      "Verb: 'replaced', Length: 8\n",
      "Text Substring: ''\n",
      "Verb: 'neededted', Length: 9\n",
      "Text Substring: ''\n",
      "Start Index: 1\n",
      "End Index: 35\n",
      "Substring between action_verbs[0] and action_verbs[1]:\n",
      " pm per scope hvac tasks \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline, logging\n",
    "\n",
    "# Suppress warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model for POS tagging\n",
    "model_name = 'vblagoje/bert-english-uncased-finetuned-pos'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Define a function to find all action verbs in the text using the BERT model\n",
    "def find_action_verbs(text, nlp_pipeline):\n",
    "    # Use the BERT model for POS tagging\n",
    "    pos_results = nlp_pipeline(text)\n",
    "    \n",
    "    # Find all action verbs and handle sub-word tokens\n",
    "    action_verbs = []\n",
    "    current_word = \"\"\n",
    "    for result in pos_results:\n",
    "        if result['entity'] == 'VERB':  # Check if the entity is a verb\n",
    "            if result['word'].startswith('##'):\n",
    "                current_word += result['word'][2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    action_verbs.append(current_word)\n",
    "                current_word = result['word']\n",
    "    if current_word:\n",
    "        action_verbs.append(current_word)\n",
    "    \n",
    "    return action_verbs\n",
    "\n",
    "# Initialize the pipeline\n",
    "nlp_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=0 if torch.backends.mps.is_available() else -1)\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\n",
    "PERFORMED PM PER SCOPE HVAC TASKS REPLACED AIR FILTERS VISUALLY INSPECTED FOR REFRIGERANT LEAKS LUBRICATED ALL BEARINGS AS NEEDED SHUT OFF WATER SUPPLY  \n",
    "FALL VISIT AS NEEDED  INSPECTED BELTS AND ADJUSTED AS NEEDED CLEANED CONDENSATE LINES CHECKED CONTACTORS VISUALLY INSPECTED EVAPORATOR AND CONDENSER COILS \n",
    "INSPECTED AND TESTED HEATING CIRCUIT FOR OPERATION INSPECTED AND TESTED EACH CONDENSATE PUMP IF APPLICABLE REFRIGERATIONS TASKS INSPECTED ALL HINGES AND \n",
    "GASKETS CHECKED ELECTRICAL CONTACTS  CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED FOR LEAKS CLEANED ALL PRE FILTER MEDIA AND \n",
    "REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS AS NEEDED CHECKED CONTROLS CALIBRATION AND \n",
    "OPERATION WALK IN TASKS INSPECFTED ALL HINGES AND GASKETS CHECKED ELECTRICAL CONTACTS CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS VISUALLY INSPECTED \n",
    "FOR LEAKS CLEANE DALL PRE FILTER MEDIA AND REPLACED IF APPLICABLE BRUSHED COIL FINS AS NEEDED INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "INSPECTED SIGHT GLASS CHECKED CONTROL CALIBRATION AND OPERATION ICE MACHINE TASKS CHECKED ICE PRODUCTION THICKNESS AND SENSING PROBES INSPECTED DOOR AND GASKET \n",
    "VISUALLY INSPECTED BIN AND BIN TSTAT INSPECTED WATER PUMPS AND DISTRIBUTION TUBES VISUALLY INSPECTED WATER FILTERS INSPECTED FOR ANY LEAKS CLEANED CONDENSER COILS \n",
    "INSPECTED ALL ELECTRICAL COMPONENTS INSPECTED FAN MOTOR  BLADES   BEARINGS   LUBRICATED AS NEEDED DESCALED ICE MACHINE EXHAUST FAN TASKS INSPECTED ROOF FAN BELTS AND \n",
    "SHEAVES ADJUSTED AS NEEDED REPLACED BELTS AS NEEDED  20X25X2 PLEATED FILTER HIGH EFFICIENCY\n",
    "\"\"\"\n",
    "\n",
    "# Remove special characters from the text\n",
    "text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "# Find all action verbs in the text\n",
    "action_verbs = find_action_verbs(text, nlp_pipeline)\n",
    "print(\"Extracted Action Verbs:\", action_verbs)\n",
    "\n",
    "# Debugging: Print the length and corresponding substring in the text\n",
    "for verb in action_verbs:\n",
    "    print(f\"Verb: '{verb}', Length: {len(verb)}\")\n",
    "    print(f\"Text Substring: '{text[text.find(verb):text.find(verb)+len(verb)]}'\")\n",
    "\n",
    "# Normalize case\n",
    "text = text.lower()\n",
    "action_verbs = [verb.lower() for verb in action_verbs]\n",
    "\n",
    "# Find the start and end indices\n",
    "start_index = text.find(action_verbs[0])\n",
    "end_index = text.find(action_verbs[1]) if len(action_verbs) > 1 else len(text)\n",
    "\n",
    "print(\"Start Index:\", start_index)\n",
    "print(\"End Index:\", end_index)\n",
    "\n",
    "# Extract the substring between the first and second verbs\n",
    "if start_index != -1 and end_index != -1:\n",
    "    substring = text[start_index + len(action_verbs[0]):end_index]\n",
    "    print(\"Substring between action_verbs[0] and action_verbs[1]:\")\n",
    "    print(substring)\n",
    "else:\n",
    "    print(\"Not enough action verbs found to extract a substring between them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
