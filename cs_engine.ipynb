{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintenance Report NLP Analysis\n",
    "\n",
    "This notebook implements an NLP pipeline for analyzing maintenance reports using BERT and NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, pipeline, logging\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Suppress warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    try:\n",
    "        # Check if GPU/MPS is available and set the device\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "        \n",
    "        # Load the pre-trained BERT model for POS tagging\n",
    "        model_name = 'vblagoje/bert-english-uncased-finetuned-pos'\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        model = BertForTokenClassification.from_pretrained(model_name).to(device)\n",
    "        \n",
    "        return tokenizer, model, device\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing model: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Initialize the model\n",
    "tokenizer, model, device = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, tokenizer, model, device):\n",
    "    try:\n",
    "        # Text preprocessing\n",
    "        text = re.sub(r'\\bas needed\\b', '', text.lower())\n",
    "        text = re.sub(r'\\s*,\\s*and\\s+', ', ', text)  # Normalize conjunctions\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        # Initialize the spell checker and lemmatizer\n",
    "        spell = SpellChecker()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        # Process the text\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged = pos_tag(tokens)\n",
    "        \n",
    "        # Extract verbs and their corresponding objects\n",
    "        verb_object_pairs = []\n",
    "        current_verb = None\n",
    "        current_objects = []\n",
    "        \n",
    "        def is_potential_verb(word, tag):\n",
    "            # Check if word ends with common past tense/participle endings\n",
    "            return (tag.startswith('VB') or tag == 'VBD' or tag == 'VBN' or \n",
    "                   (tag == 'JJ' and (word.endswith('ed') or word.endswith('en'))))\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(tagged):\n",
    "            word, tag = tagged[i]\n",
    "            \n",
    "            # Handle verbs (including past tense, participles, and adjectives that are actually verbs)\n",
    "            if is_potential_verb(word, tag):\n",
    "                # Save previous pair if exists\n",
    "                if current_verb and current_objects:\n",
    "                    verb_object_pairs.append((lemmatizer.lemmatize(current_verb, 'v'), ' '.join(current_objects)))\n",
    "                current_verb = spell.correction(word)\n",
    "                current_objects = []\n",
    "            \n",
    "            # Handle nouns, adjectives, and compound objects\n",
    "            elif (tag.startswith('NN') or \n",
    "                  (tag.startswith('JJ') and not word.endswith('ed')) or \n",
    "                  tag == 'IN' or tag.startswith('VBG')):  # Include prepositions and gerunds\n",
    "                if current_verb:\n",
    "                    temp_objects = [word]\n",
    "                    # Look ahead for compound objects and their modifiers\n",
    "                    j = i + 1\n",
    "                    while j < len(tagged) and (\n",
    "                        tagged[j][1].startswith('NN') or \n",
    "                        (tagged[j][1].startswith('JJ') and not tagged[j][0].endswith('ed')) or \n",
    "                        tagged[j][1] == 'IN' or  # Include prepositions\n",
    "                        tagged[j][1].startswith('VBG')  # Include gerunds\n",
    "                    ):\n",
    "                        temp_objects.append(tagged[j][0])\n",
    "                        j += 1\n",
    "                    \n",
    "                    # Only add if we have a meaningful object phrase\n",
    "                    if any(t[1].startswith('NN') for t in tagged[i:j]):\n",
    "                        current_objects.extend(temp_objects)\n",
    "                    i = j - 1  # Update index to skip processed compound words\n",
    "            \n",
    "            # Handle commas as phrase separators\n",
    "            elif word == ',':\n",
    "                if current_verb and current_objects:\n",
    "                    verb_object_pairs.append((lemmatizer.lemmatize(current_verb, 'v'), ' '.join(current_objects)))\n",
    "                    current_objects = []\n",
    "                    current_verb = None\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        # Add the last pair if exists\n",
    "        if current_verb and current_objects:\n",
    "            verb_object_pairs.append((lemmatizer.lemmatize(current_verb, 'v'), ' '.join(current_objects)))\n",
    "\n",
    "        return verb_object_pairs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Tasks (6):\n",
      "----------------------------------------\n",
      "• Exhaust: fan tasks\n",
      "• Perform: pm per scope hvac tasks\n",
      "• Pleat: high efficiency\n",
      "• Sense: probes\n",
      "• Shut: water supply fall visit\n",
      "• Walk: in tasks\n",
      "\n",
      "Maintenance Tasks (4):\n",
      "----------------------------------------\n",
      "• Lubricate: bearings\n",
      "• Lubricate: motors bearings\n",
      "• Replace: air filters\n",
      "• Replace: belts\n",
      "\n",
      "Inspection Tasks (19):\n",
      "----------------------------------------\n",
      "• Check: control calibration operation ice machine tasks\n",
      "• Check: controls calibration operation\n",
      "• Check: electrical contacts controls components\n",
      "• Check: ice production thickness\n",
      "• Inspect: belts\n",
      "• Inspect: bin bin tstat\n",
      "• Inspect: blower wheels fans\n",
      "• Inspect: door gasket\n",
      "• Inspect: electrical components\n",
      "• Inspect: fan motor blades bearings\n",
      "• Inspect: for leaks\n",
      "• Inspect: for refrigerant leaks\n",
      "• Inspect: hinges gaskets\n",
      "• Inspect: leaks\n",
      "• Inspect: relays contactors\n",
      "• Inspect: roof fan belts sheaves\n",
      "• Inspect: sight glass\n",
      "• Inspect: water filters\n",
      "• Inspect: water pumps distribution tubes\n",
      "\n",
      "Cleaning Tasks (5):\n",
      "----------------------------------------\n",
      "• Brush: coil fins\n",
      "• Clean: condensate lines\n",
      "• Clean: condenser coils\n",
      "• Clean: pre filter media\n",
      "• Descale: ice machine\n",
      "\n",
      "Other Tasks (6):\n",
      "----------------------------------------\n",
      "• Pleat: high efficiency\n",
      "• Walk: in tasks\n",
      "• Exhaust: fan tasks\n",
      "• Shut: water supply fall visit\n",
      "• Sense: probes\n",
      "• Perform: pm per scope hvac tasks\n",
      "\n",
      "Maintenance Tasks (4):\n",
      "----------------------------------------\n",
      "• Lubricate: motors bearings\n",
      "• Replace: air filters\n",
      "• Replace: belts\n",
      "• Lubricate: bearings\n",
      "\n",
      "Inspection Tasks (19):\n",
      "----------------------------------------\n",
      "• Inspect: water pumps distribution tubes\n",
      "• Inspect: sight glass\n",
      "• Inspect: door gasket\n",
      "• Inspect: leaks\n",
      "• Inspect: electrical components\n",
      "• Inspect: blower wheels fans\n",
      "• Check: controls calibration operation\n",
      "• Inspect: fan motor blades bearings\n",
      "• Inspect: belts\n",
      "• Check: electrical contacts controls components\n",
      "• Check: ice production thickness\n",
      "• Inspect: for refrigerant leaks\n",
      "• Inspect: roof fan belts sheaves\n",
      "• Check: control calibration operation ice machine tasks\n",
      "• Inspect: for leaks\n",
      "• Inspect: hinges gaskets\n",
      "• Inspect: relays contactors\n",
      "• Inspect: bin bin tstat\n",
      "• Inspect: water filters\n",
      "\n",
      "Cleaning Tasks (5):\n",
      "----------------------------------------\n",
      "• Descale: ice machine\n",
      "• Clean: condensate lines\n",
      "• Clean: condenser coils\n",
      "• Brush: coil fins\n",
      "• Clean: pre filter media\n",
      "\n",
      "Task Distribution:\n",
      "Other: 6 tasks (16.2%)\n",
      "Maintenance: 4 tasks (10.8%)\n",
      "Inspection: 19 tasks (51.4%)\n",
      "Cleaning: 5 tasks (13.5%)\n"
     ]
    }
   ],
   "source": [
    "# Example maintenance report text\n",
    "text = \"\"\"\n",
    "PERFORMED PM PER SCOPE HVAC TASKS REPLACED AIR FILTERS VISUALLY INSPECTED FOR REFRIGERANT LEAKS LUBRICATED ALL BEARINGS AS NEEDED SHUT OFF WATER SUPPLY \n",
    "FALL VISIT AS NEEDED  INSPECTED BELTS AND ADJUSTED AS NEEDED CLEANED CONDENSATE LINES BRUSHED COIL FINS INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "CHECKED CONTROLS CALIBRATION AND OPERATION WALK IN TASKS INSPECTED ALL HINGES AND GASKETS CHECKED ELECTRICAL CONTACTS CONTROLS AND COMPONENTS INSPECTED RELAYS AND CONTACTORS \n",
    "VISUALLY INSPECTED FOR LEAKS CLEANED ALL PRE FILTER MEDIA AND REPLACED IF APPLICABLE BRUSHED COIL FINS INSPECTED BLOWER WHEELS AND FANS LUBRICATED MOTORS AND BEARINGS \n",
    "INSPECTED SIGHT GLASS CHECKED CONTROL CALIBRATION AND OPERATION ICE MACHINE TASKS CHECKED ICE PRODUCTION THICKNESS AND SENSING PROBES INSPECTED DOOR AND GASKET VISUALLY \n",
    "INSPECTED BIN AND BIN TSTAT INSPECTED WATER PUMPS AND DISTRIBUTION TUBES VISUALLY INSPECTED WATER FILTERS INSPECTED FOR ANY LEAKS CLEANED CONDENSER COILS \n",
    "INSPECTED ALL ELECTRICAL COMPONENTS INSPECTED FAN MOTOR BLADES BEARINGS LUBRICATED DESCALED ICE MACHINE EXHAUST FAN TASKS INSPECTED ROOF FAN BELTS AND SHEAVES ADJUSTED \n",
    "REPLACED BELTS 20X25X2 PLEATED FILTER HIGH EFFICIENCY\n",
    "\"\"\"\n",
    "\n",
    "# Process the text\n",
    "results = process_text(text, tokenizer, model, device)\n",
    "\n",
    "# Print results with task categorization\n",
    "def categorize_task(verb, obj):\n",
    "    inspection_verbs = {'inspect', 'check', 'examine', 'monitor', 'observe', 'verify'}\n",
    "    cleaning_verbs = {'clean', 'brush', 'wash', 'wipe', 'descale'}\n",
    "    maintenance_verbs = {'lubricate', 'adjust', 'replace', 'repair', 'calibrate'}\n",
    "    \n",
    "    if verb in inspection_verbs:\n",
    "        return \"Inspection\"\n",
    "    elif verb in cleaning_verbs:\n",
    "        return \"Cleaning\"\n",
    "    elif verb in maintenance_verbs:\n",
    "        return \"Maintenance\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Group tasks by category\n",
    "tasks_by_category = {}\n",
    "for verb, obj in results:\n",
    "    category = categorize_task(verb, obj)\n",
    "    if category not in tasks_by_category:\n",
    "        tasks_by_category[category] = set()  # Use a set to store unique pairs\n",
    "    tasks_by_category[category].add((verb, obj))  # Add to set to ensure uniqueness\n",
    "\n",
    "# Print tasks by category\n",
    "for category in [\"Other\", \"Maintenance\", \"Inspection\", \"Cleaning\"]:\n",
    "    if category in tasks_by_category:\n",
    "        print(f\"\\n{category} Tasks ({len(tasks_by_category[category])}):\")\n",
    "        print(\"----------------------------------------\")\n",
    "        for verb, obj in sorted(tasks_by_category[category]):  # Sort for consistent order\n",
    "            print(f\"• {verb.capitalize()}: {obj}\")\n",
    "\n",
    "for category, tasks in tasks_by_category.items():\n",
    "    print(f\"\\n{category} Tasks ({len(tasks)}):\\n\" + \"-\" * 40)\n",
    "    for verb, obj in tasks:\n",
    "        print(f\"• {verb.capitalize()}: {obj}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nTask Distribution:\")\n",
    "for category, tasks in tasks_by_category.items():\n",
    "    percentage = (len(tasks) / len(results)) * 100\n",
    "    print(f\"{category}: {len(tasks)} tasks ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolsys_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
